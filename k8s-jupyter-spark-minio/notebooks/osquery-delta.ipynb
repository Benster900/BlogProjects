{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd9fd634-33db-4f7e-b137-ba8a75813b91",
   "metadata": {},
   "source": [
    "# Create PySpark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92a93274-e6bb-4416-a127-29f86f2fe47e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPARK_ENDPOINT: spark://10.152.183.194:7077\n",
      "MINIO_ENDPOINT: 10.152.183.94:9000\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "from delta import *\n",
    "import pyspark\n",
    "import os\n",
    "\n",
    "\n",
    "external_jars = [\n",
    "    \"hadoop-aws-3.3.4.jar\",\n",
    "    \"aws-java-sdk-core-1.12.599.jar\",\n",
    "    \"aws-java-sdk-s3-1.12.599.jar\",\n",
    "    \"delta-storage-3.0.0.jar\",\n",
    "    \"delta-spark_2.12-3.0.0.jar\",\n",
    "    \"aws-java-sdk-dynamodb-1.12.599.jar\",\n",
    "    \"hadoop-common-3.3.4.jar\",\n",
    "]\n",
    "\n",
    "\n",
    "SPARK_ENDPOINT = str()\n",
    "for name, value in os.environ.items():\n",
    "    if name.endswith(\"SPARK_MASTER_SVC_SERVICE_HOST\"):\n",
    "        SPARK_ENDPOINT=f\"spark://{value}:7077\"\n",
    "print(f\"SPARK_ENDPOINT: {SPARK_ENDPOINT}\")\n",
    "\n",
    "\n",
    "MINIO_ENDPOINT = str()\n",
    "for name, value in os.environ.items():\n",
    "    if name.endswith(\"_MINIO_PORT\"):\n",
    "        MINIO_ENDPOINT=value.replace(\"tcp://\", \"\")\n",
    "print(f\"MINIO_ENDPOINT: {MINIO_ENDPOINT}\")\n",
    "\n",
    "\n",
    "builder = (\n",
    "    pyspark.sql.SparkSession.builder.appName(\"Myapp\")\n",
    "    # Sets the Spark master/captain URL to connect too.\n",
    "    .master(SPARK_ENDPOINT)\n",
    "    # JARs on disk to load into our Spark session\n",
    "    .config(\"spark.jars\", \",\".join(external_jars))\n",
    "    # k8s service for Jupyter driver\n",
    "    .config(\"spark.driver.host\", \"jupyter-driver\")\n",
    "    # Port for Jupyter driver\n",
    "    .config(\"spark.driver.port\", 2222)\n",
    "    # Extending the capabilities of SQL searching with Delta tables\n",
    "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\")\n",
    "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\")\n",
    "    .config(\"spark.hadoop.fs.s3a.aws.credentials.provider\", 'org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider')\n",
    "    ####### AWS setup and creds #######\n",
    "    .config(\"spark.hadoop.fs.s3a.access.key\", \"analyst\")\n",
    "    .config(\"spark.hadoop.fs.s3a.secret.key\", \"analyst123\")\n",
    "    .config(\"spark.hadoop.fs.s3a.endpoint\", MINIO_ENDPOINT)\n",
    "    .config(\"spark.hadoop.fs.s3a.connection.ssl.enabled\", \"false\")\n",
    "    .config(\"spark.hadoop.fs.s3a.impl\",\"org.apache.hadoop.fs.s3a.S3AFileSystem\")\n",
    "    .config(\"spark.hadoop.fs.s3a.path.style.access\", \"true\")\n",
    "    .config(\"spark.hadoop.fs.s3a.attempts.maximum\", \"1\")\n",
    "    .config(\"spark.hadoop.fs.s3a.connection.establish.timeout\", \"5000\")\n",
    "    .config(\"spark.hadoop.fs.s3a.connection.timeout\", \"10000\")\n",
    ")\n",
    "spark = configure_spark_with_delta_pip(builder).getOrCreate()\n",
    "\n",
    "print (\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54602f4d-eb45-42ed-9693-9fe8c49f791a",
   "metadata": {},
   "source": [
    "# Osquery bronze schema\n",
    "\n",
    "This segment of code will read the raw log data from S3 and into dataframe using a schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e051cbc-f34c-48e7-99b6-d0c07ac3fc8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+--------------------+--------+--------------------+--------+------------------+-----+--------------------+--------------------+---------+--------------------+\n",
      "|          @timestamp|@version|               agent|     ecs|               event| fileset|              host|input|                json|                 log|  service|                tags|\n",
      "+--------------------+--------+--------------------+--------+--------------------+--------+------------------+-----+--------------------+--------------------+---------+--------------------+\n",
      "|2022-02-12T18:21:...|       1|{1f678581-8e27-4b...|{1.12.0}|{osquery.result, ...|{result}|{ip-172-16-55-120}|{log}|{removed, Sat Feb...|{{/var/log/osquer...|{osquery}|[beats_input_raw_...|\n",
      "|2022-02-12T18:21:...|       1|{1f678581-8e27-4b...|{1.12.0}|{osquery.result, ...|{result}|{ip-172-16-55-120}|{log}|{added, Sat Feb 1...|{{/var/log/osquer...|{osquery}|[beats_input_raw_...|\n",
      "|2022-02-12T18:21:...|       1|{1f678581-8e27-4b...|{1.12.0}|{osquery.result, ...|{result}|{ip-172-16-55-120}|{log}|{added, Sat Feb 1...|{{/var/log/osquer...|{osquery}|[beats_input_raw_...|\n",
      "|2022-02-12T18:21:...|       1|{1f678581-8e27-4b...|{1.12.0}|{osquery.result, ...|{result}|{ip-172-16-55-120}|{log}|{removed, Sat Feb...|{{/var/log/osquer...|{osquery}|[beats_input_raw_...|\n",
      "|2022-02-12T18:21:...|       1|{1f678581-8e27-4b...|{1.12.0}|{osquery.result, ...|{result}|{ip-172-16-55-120}|{log}|{added, Sat Feb 1...|{{/var/log/osquer...|{osquery}|[beats_input_raw_...|\n",
      "|2022-02-12T18:21:...|       1|{1f678581-8e27-4b...|{1.12.0}|{osquery.result, ...|{result}|{ip-172-16-55-120}|{log}|{removed, Sat Feb...|{{/var/log/osquer...|{osquery}|[beats_input_raw_...|\n",
      "|2022-02-12T18:21:...|       1|{1f678581-8e27-4b...|{1.12.0}|{osquery.result, ...|{result}|{ip-172-16-55-120}|{log}|{added, Sat Feb 1...|{{/var/log/osquer...|{osquery}|[beats_input_raw_...|\n",
      "|2022-02-12T18:21:...|       1|{1f678581-8e27-4b...|{1.12.0}|{osquery.result, ...|{result}|{ip-172-16-55-120}|{log}|{removed, Sat Feb...|{{/var/log/osquer...|{osquery}|[beats_input_raw_...|\n",
      "|2022-02-12T18:21:...|       1|{1f678581-8e27-4b...|{1.12.0}|{osquery.result, ...|{result}|{ip-172-16-55-120}|{log}|{added, Sat Feb 1...|{{/var/log/osquer...|{osquery}|[beats_input_raw_...|\n",
      "|2022-02-12T18:21:...|       1|{1f678581-8e27-4b...|{1.12.0}|{osquery.result, ...|{result}|{ip-172-16-55-120}|{log}|{added, Sat Feb 1...|{{/var/log/osquer...|{osquery}|[beats_input_raw_...|\n",
      "|2022-02-12T18:21:...|       1|{1f678581-8e27-4b...|{1.12.0}|{osquery.result, ...|{result}|{ip-172-16-55-120}|{log}|{removed, Sat Feb...|{{/var/log/osquer...|{osquery}|[beats_input_raw_...|\n",
      "|2022-02-12T18:21:...|       1|{1f678581-8e27-4b...|{1.12.0}|{osquery.result, ...|{result}|{ip-172-16-55-120}|{log}|{added, Sat Feb 1...|{{/var/log/osquer...|{osquery}|[beats_input_raw_...|\n",
      "|2022-02-12T18:21:...|       1|{1f678581-8e27-4b...|{1.12.0}|{osquery.result, ...|{result}|{ip-172-16-55-120}|{log}|{removed, Sat Feb...|{{/var/log/osquer...|{osquery}|[beats_input_raw_...|\n",
      "|2022-02-12T18:21:...|       1|{1f678581-8e27-4b...|{1.12.0}|{osquery.result, ...|{result}|{ip-172-16-55-120}|{log}|{removed, Sat Feb...|{{/var/log/osquer...|{osquery}|[beats_input_raw_...|\n",
      "|2022-02-12T18:21:...|       1|{1f678581-8e27-4b...|{1.12.0}|{osquery.result, ...|{result}|{ip-172-16-55-120}|{log}|{added, Sat Feb 1...|{{/var/log/osquer...|{osquery}|[beats_input_raw_...|\n",
      "|2022-02-12T18:21:...|       1|{1f678581-8e27-4b...|{1.12.0}|{osquery.result, ...|{result}|{ip-172-16-55-120}|{log}|{added, Sat Feb 1...|{{/var/log/osquer...|{osquery}|[beats_input_raw_...|\n",
      "|2022-02-12T18:22:...|       1|{1f678581-8e27-4b...|{1.12.0}|{osquery.result, ...|{result}|{ip-172-16-55-120}|{log}|{removed, Sat Feb...|{{/var/log/osquer...|{osquery}|[beats_input_raw_...|\n",
      "|2022-02-12T18:22:...|       1|{1f678581-8e27-4b...|{1.12.0}|{osquery.result, ...|{result}|{ip-172-16-55-120}|{log}|{removed, Sat Feb...|{{/var/log/osquer...|{osquery}|[beats_input_raw_...|\n",
      "|2022-02-12T18:22:...|       1|{1f678581-8e27-4b...|{1.12.0}|{osquery.result, ...|{result}|{ip-172-16-55-120}|{log}|{added, Sat Feb 1...|{{/var/log/osquer...|{osquery}|[beats_input_raw_...|\n",
      "|2022-02-12T18:22:...|       1|{1f678581-8e27-4b...|{1.12.0}|{osquery.result, ...|{result}|{ip-172-16-55-120}|{log}|{added, Sat Feb 1...|{{/var/log/osquer...|{osquery}|[beats_input_raw_...|\n",
      "+--------------------+--------+--------------------+--------+--------------------+--------+------------------+-----+--------------------+--------------------+---------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import (\n",
    "    StructField,\n",
    "    StringType,\n",
    "    MapType,\n",
    "    LongType,\n",
    "    IntegerType,\n",
    "    ArrayType,\n",
    "    StructType\n",
    ")\n",
    "\n",
    "osquery_bronze_schema = StructType([\n",
    "    StructField(\"@timestamp\",StringType(),True),\n",
    "    StructField(\"@version\",StringType(),True),\n",
    "    StructField('agent', StructType([\n",
    "         StructField('ephemeral_id', StringType(), True),\n",
    "         StructField('hostname', StringType(), True),\n",
    "         StructField('name', StringType(), True),\n",
    "         StructField('type', StringType(), True),\n",
    "         StructField('version', StringType(), True),\n",
    "    ])),\n",
    "    StructField('ecs', StructType([\n",
    "         StructField('version', StringType(), True),\n",
    "    ])),\n",
    "    StructField('event', StructType([\n",
    "         StructField('dataset', StringType(), True),\n",
    "         StructField('module', StringType(), True),\n",
    "    ])),\n",
    "    StructField('fileset', StructType([\n",
    "         StructField('name', StringType(), True),\n",
    "    ])),\n",
    "    StructField('host', StructType([\n",
    "         StructField('name', StringType(), True),\n",
    "    ])),\n",
    "    StructField('input', StructType([\n",
    "         StructField('type', StringType(), True),\n",
    "    ])),\n",
    "    StructField('json', StructType([\n",
    "         StructField('action', StringType(), True),\n",
    "        StructField('calendarTime', StringType(), True),\n",
    "        StructField('columns', MapType(StringType(),StringType()), True),\n",
    "        StructField('counter', IntegerType(), True),\n",
    "        StructField('epoch', LongType(), True),\n",
    "        StructField('unixTime', LongType(), True),\n",
    "        StructField('numerics', IntegerType(), True),\n",
    "        StructField('name', StringType(), True),\n",
    "        StructField('hostIdentifier', StringType(), True),\n",
    "    ])),\n",
    "    StructField('log', StructType([\n",
    "        StructField('file', StructType([\n",
    "            StructField('path', StringType(), True),\n",
    "        ])),\n",
    "        StructField('offset', LongType(), True),\n",
    "    ])),\n",
    "    StructField('service', StructType([\n",
    "         StructField('type', StringType(), True),\n",
    "    ])),\n",
    "    StructField(\"tags\",ArrayType(StringType()),True),\n",
    "])\n",
    "\n",
    "df = spark.read.schema(osquery_bronze_schema).json(\"s3a://logs-bronze/osquery/osquery-*log\")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a55c41-bfa7-4db0-ab8b-60b31a5e3df3",
   "metadata": {},
   "source": [
    "# Drop metadata columns\n",
    "Filebeat includes a bunch of metadata about the agent sending the logs that we don't need. This section will drop these unnecessary fields. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b6789f0-e341-460f-a465-2132801023c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "osquery_bronze = df\n",
    "drop_metadata_columns = [\n",
    "    \"@timestamp\",\n",
    "    \"@version\",\n",
    "    \"agent\",\n",
    "    \"ecs\",\n",
    "    \"input\",\n",
    "    \"log\",\n",
    "    \"tags\",\n",
    "    \"fileset\",\n",
    "    \"service\",\n",
    "]\n",
    "osquery_silver_no_metadata = osquery_bronze.drop(*drop_metadata_columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af80b69a-559f-4e3a-9731-290a6f56b99b",
   "metadata": {},
   "source": [
    "# Rename columns and pull data to top level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f641a61-bd7c-45ed-9ed2-96e16370ba33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-------+--------------------+----------+--------------------+\n",
      "|        hostname| action|               table|  unixTime|             columns|\n",
      "+----------------+-------+--------------------+----------+--------------------+\n",
      "|ip-172-16-55-120|removed|            cpu_time|1644690067|{user -> 26696, s...|\n",
      "|ip-172-16-55-120|  added|            cpu_time|1644690067|{user -> 26699, s...|\n",
      "|ip-172-16-55-120|  added|       syslog_events|1644690073|{severity -> 6, t...|\n",
      "|ip-172-16-55-120|removed|            cpu_time|1644690067|{user -> 27158, s...|\n",
      "|ip-172-16-55-120|  added|            cpu_time|1644690067|{user -> 27165, s...|\n",
      "|ip-172-16-55-120|removed|pack_incident-res...|1644690077|{pid -> 28733, ty...|\n",
      "|ip-172-16-55-120|  added|      process_events|1644690086|{path -> /usr/bin...|\n",
      "|ip-172-16-55-120|removed|         memory_info|1644690094|{buffers -> 62951...|\n",
      "|ip-172-16-55-120|  added|         memory_info|1644690094|{buffers -> 62959...|\n",
      "|ip-172-16-55-120|  added|       syslog_events|1644690100|{datetime -> 2022...|\n",
      "|ip-172-16-55-120|removed|        runtime_perf|1644690101|{config_hash -> 0...|\n",
      "|ip-172-16-55-120|  added|        runtime_perf|1644690101|{watcher -> 491, ...|\n",
      "|ip-172-16-55-120|removed|            iptables|1644690103|{dst_port -> , pr...|\n",
      "|ip-172-16-55-120|removed|            iptables|1644690103|{dst_port -> , pr...|\n",
      "|ip-172-16-55-120|  added|            iptables|1644690103|{dst_port -> , pr...|\n",
      "|ip-172-16-55-120|  added|            iptables|1644690103|{dst_port -> , pr...|\n",
      "|ip-172-16-55-120|removed|            cpu_time|1644690128|{user -> 26699, s...|\n",
      "|ip-172-16-55-120|removed|            cpu_time|1644690128|{user -> 27165, s...|\n",
      "|ip-172-16-55-120|  added|            cpu_time|1644690128|{user -> 26706, s...|\n",
      "|ip-172-16-55-120|  added|            cpu_time|1644690128|{user -> 27174, s...|\n",
      "+----------------+-------+--------------------+----------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "\n",
    "osquery_silver = osquery_silver_no_metadata.select(\n",
    "    col(\"json.hostIdentifier\").alias(\"hostname\"),\n",
    "    col(\"json.action\").alias(\"action\"),\n",
    "    col(\"json.name\").alias(\"table\"),\n",
    "    col(\"json.unixTime\").alias(\"unixTime\"),\n",
    "    col(\"json.columns\").alias(\"columns\"),\n",
    ")\n",
    "\n",
    "osquery_silver.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a9b6435-256d-4b84-865b-0a92bae70e14",
   "metadata": {},
   "source": [
    "# Write dataframe as Delta Lake table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0587069-a6cf-4d84-865b-b54c6a9ebf6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "osquery_silver.write \\\n",
    "    .format(\"delta\") \\\n",
    "    .mode('overwrite') \\\n",
    "    .save(\"s3a://logs-silver/osquery/osquery.delta\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2e8a479-38ab-4a69-ba96-ee1c2ee0c656",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
